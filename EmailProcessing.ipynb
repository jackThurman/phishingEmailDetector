{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jackt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jackt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import shutil\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Safe Email = 0\n",
    "# Phishing Email = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Email Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ceas Emails: 39154\n",
      "Nazario Emails: 1565\n",
      "Nigerian Scammer Emails: 3332\n",
      "Spam Assasin Emails: 5809\n"
     ]
    }
   ],
   "source": [
    "ceas = pd.read_csv('Datasets/Email/CEAS_08.csv')\n",
    "ling = pd.read_csv('Datasets/Email/Ling.csv')\n",
    "nazario = pd.read_csv('Datasets/Email/Nazario.csv')\n",
    "nigerian = pd.read_csv('Datasets/Email/Nigerian_Fraud.csv')\n",
    "spamAssasin = pd.read_csv('Datasets/Email/SpamAssasin.csv')\n",
    "\n",
    "dropColumns = ['sender','receiver','date','urls']\n",
    "ceas  = ceas.drop(dropColumns,axis=1)\n",
    "nazario = nazario.drop(dropColumns,axis=1)\n",
    "nigerian = nigerian.drop(dropColumns,axis=1)\n",
    "spamAssasin = spamAssasin.drop(dropColumns,axis=1)\n",
    "print('Ceas Emails: '+ str(ceas.shape[0]))\n",
    "print('Nazario Emails: '+ str(nazario.shape[0]))\n",
    "print('Nigerian Scammer Emails: '+ str(nigerian.shape[0]))\n",
    "print('Spam Assasin Emails: '+ str(spamAssasin.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enron Email Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enron Emails: 29767\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpl nom for may 25 , 2001</td>\n",
       "      <td>( see attached file : hplno 525 . xls )\\r\\n- h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>re : nom / actual vols for 24 th</td>\n",
       "      <td>- - - - - - - - - - - - - - - - - - - - - - fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enron actuals for march 30 - april 1 , 201</td>\n",
       "      <td>estimated actuals\\r\\nmarch 30 , 2001\\r\\nno flo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpl nom for may 30 , 2001</td>\n",
       "      <td>( see attached file : hplno 530 . xls )\\r\\n- h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpl nom for june 1 , 2001</td>\n",
       "      <td>( see attached file : hplno 601 . xls )\\r\\n- h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      subject  \\\n",
       "0                   hpl nom for may 25 , 2001   \n",
       "1            re : nom / actual vols for 24 th   \n",
       "2  enron actuals for march 30 - april 1 , 201   \n",
       "3                   hpl nom for may 30 , 2001   \n",
       "4                   hpl nom for june 1 , 2001   \n",
       "\n",
       "                                                body  label  \n",
       "0  ( see attached file : hplno 525 . xls )\\r\\n- h...      0  \n",
       "1  - - - - - - - - - - - - - - - - - - - - - - fo...      0  \n",
       "2  estimated actuals\\r\\nmarch 30 , 2001\\r\\nno flo...      0  \n",
       "3  ( see attached file : hplno 530 . xls )\\r\\n- h...      0  \n",
       "4  ( see attached file : hplno 601 . xls )\\r\\n- h...      0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron = pd.read_csv('Datasets/Email/Enron.csv')\n",
    "print('Enron Emails: '+ str(enron.shape[0]))\n",
    "enron.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spear Fishing Email Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spear Phishing Emails: 334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Important Information - Action Required</td>\n",
       "      <td>&lt;html&gt;&lt;body style='background-color:white;'&gt;&lt;h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Invitation to Cutting-Edge Cybersecurity Webinar</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;h3&gt;Dear Gale Robinson,&lt;/h3&gt;&lt;p&gt;I h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Important Announcement from SafeSecurity</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;p&gt;Dear Jennifer,&lt;/p&gt;&lt;br&gt;&lt;p&gt;I hope...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Important Information Regarding Cybersecurity</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;h3&gt;Dear Ethan Hawk,&lt;/h3&gt;&lt;p&gt;I hope...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Important Update Regarding Cybersecurity</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;h2&gt;Dear Moses Sharp,&lt;/h2&gt;&lt;p&gt;We ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            subject  \\\n",
       "0           Important Information - Action Required   \n",
       "1  Invitation to Cutting-Edge Cybersecurity Webinar   \n",
       "2          Important Announcement from SafeSecurity   \n",
       "3     Important Information Regarding Cybersecurity   \n",
       "4          Important Update Regarding Cybersecurity   \n",
       "\n",
       "                                                body  label  \n",
       "0  <html><body style='background-color:white;'><h...      0  \n",
       "1  <html><body><h3>Dear Gale Robinson,</h3><p>I h...      0  \n",
       "2  <html><body><p>Dear Jennifer,</p><br><p>I hope...      0  \n",
       "3  <html><body><h3>Dear Ethan Hawk,</h3><p>I hope...      0  \n",
       "4  <html><body><h2>Dear Moses Sharp,</h2><p>We ho...      0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spear = pd.DataFrame()\n",
    "\n",
    "directory = 'Datasets/Email/spear_phishing'\n",
    "for file in os.listdir(directory):\n",
    "    filepath = os.path.join(directory, file)\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    temp = pd.DataFrame([data])\n",
    "    spear = pd.concat([spear, temp], ignore_index=True) \n",
    "\n",
    "spear = spear.drop(['sender_name'],axis=1)  \n",
    "spear = spear.rename(columns={'email_subject': 'subject', 'email_body': 'body'})\n",
    "spear['label'] = 0\n",
    "\n",
    "print('Spear Phishing Emails: '+ str(spear.shape[0]))\n",
    "\n",
    "spear.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMS Messages: 5971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackt\\AppData\\Local\\Temp\\ipykernel_14644\\2980140685.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  sms['label'] = sms['label'].replace(['Spam','Smishing','smishing','spam'], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your opinion about me? 1. Over 2. Jada 3. Kusr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's up? Do you want me to come online? If y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So u workin overtime nigpun?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Also sir, i sent you an email about how to log...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please Stay At Home. To encourage the notion o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5961</th>\n",
       "      <td>Kay... Since we are out already</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5962</th>\n",
       "      <td>Ü log off 4 wat. It's sdryb8i</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5963</th>\n",
       "      <td>call now 08707509020 Just 20p per min NTT Ltd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5964</th>\n",
       "      <td>Are you angry with me. What happen dear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965</th>\n",
       "      <td>I'm in class. Did you get my text.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5966 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  label\n",
       "0     Your opinion about me? 1. Over 2. Jada 3. Kusr...      0\n",
       "1     What's up? Do you want me to come online? If y...      0\n",
       "2                          So u workin overtime nigpun?      0\n",
       "3     Also sir, i sent you an email about how to log...      0\n",
       "4     Please Stay At Home. To encourage the notion o...      1\n",
       "...                                                 ...    ...\n",
       "5961                    Kay... Since we are out already      0\n",
       "5962                      Ü log off 4 wat. It's sdryb8i      0\n",
       "5963   call now 08707509020 Just 20p per min NTT Ltd...      1\n",
       "5964            Are you angry with me. What happen dear      0\n",
       "5965                 I'm in class. Did you get my text.      0\n",
       "\n",
       "[5966 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tidy up SMS data so it can be concat on email data\n",
    "sms = pd.read_csv('Datasets/SMS/Dataset_5971.csv')\n",
    "sms = sms.drop(['URL','EMAIL','PHONE'],axis=1)\n",
    "\n",
    "sms = sms.rename(columns={'LABEL': 'label', 'TEXT': 'body'})\n",
    "sms = sms[['body', 'label']]\n",
    "\n",
    "# Change all labels to match labels I am using in email dataset\n",
    "sms['label'] = sms['label'].replace(['ham'], 0)\n",
    "sms['label'] = sms['label'].replace(['Spam','Smishing','smishing','spam'], 1)\n",
    "\n",
    "print('SMS Messages: '+ str(sms.shape[0]))\n",
    "sms.head(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data Points: 88791\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Never agree to be a loser</td>\n",
       "      <td>Buck up, your troubles caused by small dimensi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Befriend Jenna Jameson</td>\n",
       "      <td>\\nUpgrade your sex and pleasures with these te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN.com Daily Top 10</td>\n",
       "      <td>&gt;+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: svn commit: r619753 - in /spamassassin/tru...</td>\n",
       "      <td>Would anyone object to removing .so from this ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SpecialPricesPharmMoreinfo</td>\n",
       "      <td>\\nWelcomeFastShippingCustomerSupport\\nhttp://7...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5961</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Kay... Since we are out already</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5962</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ü log off 4 wat. It's sdryb8i</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5963</th>\n",
       "      <td>NaN</td>\n",
       "      <td>call now 08707509020 Just 20p per min NTT Ltd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5964</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Are you angry with me. What happen dear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965</th>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm in class. Did you get my text.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88786 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                subject  \\\n",
       "0                             Never agree to be a loser   \n",
       "1                                Befriend Jenna Jameson   \n",
       "2                                  CNN.com Daily Top 10   \n",
       "3     Re: svn commit: r619753 - in /spamassassin/tru...   \n",
       "4                            SpecialPricesPharmMoreinfo   \n",
       "...                                                 ...   \n",
       "5961                                                NaN   \n",
       "5962                                                NaN   \n",
       "5963                                                NaN   \n",
       "5964                                                NaN   \n",
       "5965                                                NaN   \n",
       "\n",
       "                                                   body  label  \n",
       "0     Buck up, your troubles caused by small dimensi...      1  \n",
       "1     \\nUpgrade your sex and pleasures with these te...      1  \n",
       "2     >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...      1  \n",
       "3     Would anyone object to removing .so from this ...      0  \n",
       "4     \\nWelcomeFastShippingCustomerSupport\\nhttp://7...      1  \n",
       "...                                                 ...    ...  \n",
       "5961                    Kay... Since we are out already      0  \n",
       "5962                      Ü log off 4 wat. It's sdryb8i      0  \n",
       "5963   call now 08707509020 Just 20p per min NTT Ltd...      1  \n",
       "5964            Are you angry with me. What happen dear      0  \n",
       "5965                 I'm in class. Did you get my text.      0  \n",
       "\n",
       "[88786 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat all datasets\n",
    "combined = pd.concat([ceas,enron,ling,nazario,nigerian,spamAssasin,spear,sms],axis=0)\n",
    "print('Total Data Points: '+ str(combined.shape[0]))\n",
    "combined.head(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and Normalising Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values:\n",
      " 0\n",
      "Number of blank values:\n",
      " 0\n",
      "Number of dupe:\n",
      " 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>buck trouble caused small dimension soon becom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>upgrade sex pleasure technique befriend jenna ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>daily top cnncom top video story aug pm edt to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>would anyone object removing list tld basicall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>welcomefastshippingcustomersupport specialpric...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  buck trouble caused small dimension soon becom...\n",
       "1      1  upgrade sex pleasure technique befriend jenna ...\n",
       "2      1  daily top cnncom top video story aug pm edt to...\n",
       "3      0  would anyone object removing list tld basicall...\n",
       "4      1  welcomefastshippingcustomersupport specialpric..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine subject and body\n",
    "combined.fillna({'subject': ''}, inplace=True)\n",
    "combined.fillna({'body': ''}, inplace=True)\n",
    "combined['text'] = combined['body'] + ' ' + combined['subject']\n",
    "combined = combined.drop(['subject','body'],axis=1)\n",
    "\n",
    "# Remove NaN and blank\n",
    "combined = combined[combined['text'] != '']\n",
    "null_count = combined.isnull().sum().sum()\n",
    "print('Number of null values:\\n', null_count)\n",
    "blank_count = (combined['text']=='').sum()\n",
    "print('Number of blank values:\\n',blank_count)\n",
    "\n",
    "# Remove duplicates\n",
    "combined.drop_duplicates(subset='text', keep='first', inplace=True)\n",
    "dupe_count = combined.duplicated(keep='first').sum()\n",
    "print('Number of dupe:\\n', dupe_count)\n",
    "\n",
    "# Extract embedded links\n",
    "def extract_urls(text):\n",
    "    url_pattern = re.compile(r'http[s]?://\\S+')\n",
    "    urls = url_pattern.findall(text)\n",
    "    return urls\n",
    "\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'http[s]?://\\S+')\n",
    "    return url_pattern.sub('', text)\n",
    "\n",
    "#combined['urls'] = combined['text'].apply(extract_urls)\n",
    "combined['text'] = combined['text'].apply(remove_urls)\n",
    "\n",
    "# Training the body classification model only requires email bodies and does not need links\n",
    "# Different model will be trained to classify links using the link dataset\n",
    "# So for the training set links will be removed\n",
    "\n",
    "def clean_text(text):\n",
    "    # punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # multiple whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # lower case\n",
    "    text = text.lower()\n",
    "    # stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    # stemming\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "    return text\n",
    "\n",
    "# remove html tags, keep form tags maybe\n",
    "def remove_html_tags_excluding(text, exclude_tags=['form']):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    exclude_tags = [tag.lower() for tag in exclude_tags]\n",
    "\n",
    "    # Remove all tags except the ones in the exclude list\n",
    "    for tag in soup.find_all(True):\n",
    "        if tag.name.lower() not in exclude_tags:\n",
    "            tag.unwrap()\n",
    "\n",
    "    return str(soup)\n",
    "\n",
    "# remove infrequent words\n",
    "\n",
    "\n",
    "# See if Keras can clean and normalise for me\n",
    "combined['text'] = combined['text'].apply(clean_text)\n",
    "combined['text'] = combined['text'].apply(remove_html_tags_excluding)\n",
    "\n",
    "combined.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance label weightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe Emails:  44763\n",
      "Phishing Emails:  44006\n",
      "Safe Emails:  44006\n",
      "Phishing Emails:  44006\n",
      "Combined Emails:  88012\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>would anyone object removing list tld basicall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>wrzzpvsidneycom changed removed added otherbug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>plelim remind certificate needed hurry expedit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>carlos e r wrote begin pgp signed message hash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>steve jacob wrote forwarded message steve jaco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                               text\n",
       "3       0  would anyone object removing list tld basicall...\n",
       "8       0  wrzzpvsidneycom changed removed added otherbug...\n",
       "15      0  plelim remind certificate needed hurry expedit...\n",
       "18      0  carlos e r wrote begin pgp signed message hash...\n",
       "19      0  steve jacob wrote forwarded message steve jaco..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into safe and phishing emails\n",
    "safeEmails = combined.loc[combined['label'] == 0]\n",
    "phishingEmails = combined.loc[combined['label'] == 1]\n",
    "print('Safe Emails: ',str(safeEmails.shape[0]))\n",
    "print('Phishing Emails: ',str(phishingEmails.shape[0]))\n",
    "\n",
    "# Shrink datasets to the same size to ensure fairness in training\n",
    "safeEmails = safeEmails.head(phishingEmails.shape[0])\n",
    "\n",
    "print('Safe Emails: ',str(safeEmails.shape[0]))\n",
    "print('Phishing Emails: ',str(phishingEmails.shape[0]))\n",
    "\n",
    "combined = pd.concat([safeEmails,phishingEmails],axis=0)\n",
    "print('Combined Emails: ',str(combined.shape[0]))\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write data to two folders in with each email being a .txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for index, row in combined.iterrows():\n",
    "    label = row['label']\n",
    "    text = row['text']\n",
    "    \n",
    "    file_name = f\"email_{index}.txt\"\n",
    "\n",
    "    if label == 0:\n",
    "        directory = 'Keras/benign'\n",
    "    elif label == 1:\n",
    "        directory = 'Keras/malicious'\n",
    "\n",
    "    file_path = f'{directory}/{file_name}'\n",
    "\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Dataframe as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.reset_index(drop=True)\n",
    "combined = combined[['text','label']]\n",
    "combined.to_csv('Datasets/ProcessedEmails.csv',index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
